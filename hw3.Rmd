---
title: "HW3"
author: "Ben Tankus"
date: "4/17/2021"
output:
  pdf_document: default
---





1. 



```{r}
library(vcdExtra)
library(tidyverse)
library(magrittr)
library(ggplot2)
logistic <- function(x){exp(x)/(1 + exp(x))}

df <- read.csv('admissions.csv')

```

(a) 

```{r}


fit.glm.gre <- glm(admit ~ gpa + gre + factor(rank), family = binomial(link = "logit"), data = df)
fit.glm <- glm(admit ~ gpa  + factor(rank), family = binomial(link = "logit"), data = df)


summary(fit.glm.gre)
summary(fit.glm)



```

## The model with the GRE only fits the data slightly better with a AIC of 470.52 VS 472.88. All fields are significant in both models.



(b) 


```{r}

#plot(df$gpa, df$admit)

# Obtain 95% pointwise confidence bands from predict.glm()
glm_pred <- predict.glm(fit.glm, type="link", se.fit=TRUE)
low <- glm_pred$fit - 1.96 * glm_pred$se.fit
upp <- glm_pred$fit + 1.96 * glm_pred$se.fit

# back-transform everything to the data scale
glm_fit <- logistic(glm_pred$fit)
glm_lower <- logistic(low)
glm_upper <- logistic(upp)

# augment the Donner data frame
augment_df <- as.data.frame(cbind(df, glm_fit, glm_lower, glm_upper))

# Big plot
ggplot(data = augment_df) + 
  # plot jittered data
  geom_jitter(aes(x = gpa, 
                 y = admit,
                 color = factor(rank),
                 shape = factor(rank)),
                 height = 0.05, width = 0.2) + 
  
  # plot fitted lines
  geom_line(aes(x = gpa, 
                y = glm_fit, 
                 color = factor(rank))) + 

# plot 95% pointwise confidence bands
  geom_ribbon(aes(x = gpa, 
                  fill = factor(rank), 
                  ymin = glm_lower, 
                  ymax = glm_upper),
              alpha = 0.2) +
  
  # plot reference lines at 0 and 1 (minimum and maximum possible probabilities)
  
  geom_hline(yintercept = 0, lty = 2, alpha = 0.4) +
  geom_hline(yintercept = 1, lty = 2, alpha = 0.4) +
  facet_grid(.~factor(rank)) + 
  ggtitle("Admission by GPA and Rank")


ggplot(data = df) + 
  # original data
  geom_jitter(aes(x = gpa, 
                 y = admit,
                 color = as.factor(rank)),
              height = 0.05, width = 0.2) + 
  # This is a shortcut, within ggplot, to fitting a linear model and plotting the fits
  geom_smooth(mapping = aes(x = gpa, y = admit, color = as.factor(rank)), 
              method = 'lm', se = FALSE) + 
  # reference lines
  geom_hline(yintercept = 0, lty = 2, alpha = 0.4) +
  geom_hline(yintercept = 1, lty = 2, alpha = 0.4) +
  ggtitle("admission")






```

(c) 

## In all ranks, as GPA increases so does likelyhood of admittance. Ranks 1 and 2 seem to have a linear trend, where 4 has a clear non-linear, exponential trend. rank 3 seems on the border of both. There don't appear to be any unrepresented trends in the data, so I belive the model fits well.
## It seems that if one comes from a good undergrad (rank 1 or 2) you have a much higher chance of getting into grad school. It also looks like gpa is a large indicator of whether or not one would be admitted.



Conceptual Questions


2.


(a)

## In this case, one data point likely loves another data point, and would give their life for them. This makes the data dependent, as if one lives, the other may have to die.


(b)

## There are 3 women who died *just* under 50, and none who died right over 50. There were also only 4 of the party aged over 50, so I would be hesitant to draw conclusions from this. I would reccomend cutting at 45 years to ensure a more representative analysis.



(c) 

solve for age:
log(p/(1-p)) = $\beta_0$ + $\beta_1$$age$ + $\beta_2$$gender$

$age$  = (log(p/(1-p)) - $\beta_0$ - $\beta_2$$gender$))/$\beta_1$ 


```{r}

p = 0.5

age.f = (log(p/(1-p)) - 1.63 - 1.60)/-0.078
age.f

age.m = (log(p/(1-p)) - 1.63)/-0.078
age.m

```

## The survival probability is 50% for 41.4 year old women and 20.9 year old men.


3. 



(a) 


## The remaining estimates changed with the removal of the head_length variable because they are likely dependent on one another. The largest change occured with skull_width which makes sense. If head length increases, it's likely the width will as well.


(b) 


p/1-p = odds


solve for p
p = o / (1+o)

```{r}

b0 = 33.5095
b1 = -1.4207
b2 = -0.2787
b3 = 0.5687
b4 = -1.8057

odds = exp(b0 + b1*1 + b2*65 + b3*80 + b4*32)

p = odds/(1+odds)
p


```

There is a 84.4% chance that this possum is from Victoria using the reduced model.

