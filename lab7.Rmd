---
title: "lab7"
author: "Ben Tankus"
date: "5/13/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(robustbase) # contains data we'll use
library(ggplot2)
library(vcdExtra)
library(magrittr)
library(MASS)
library(lme4)     # access the mixed functions

```

# Lab Questions

In the `epilepsy` data, we really need to use a mixed effects model to account for the fact that observations within a subject are almost certainly not independent. Let's suppose, however, that we are a naive statistician and do not realize that we need to account for this within subject correlation. Instead we fit a Poisson GLM and completely ignore the fact that we have non-independent observations (to be clear, this is **not** a correct way to do the analysis, but we are fitting the model to compare the results we get to the results from the more appropriate GLMM we fit above).

Please write 1-2 sentences in response to the following questions.

```{r}
epil_long <- gather(epilepsy,key = Visit,value = Seizures, Y1, Y2, Y3, Y4)

mod3 <- glmer.nb(Seizures ~ Trt + Age + Base + Visit + (1|ID), data = epil_long)
mod.norand <- glm.nb(Seizures ~ Trt + Age + Base + Visit, data = epil_long)
summary(mod.norand)
```

```{r}
summary(mod3)$coefficients
summary(mod.norand)$coefficients
```

1.) How do the coefficient estimates for the fixed effects compare in the two models? Why do you think the coefficient estimates are approximately the same or very different?


## The coefficients for the fixed effects model are similar to the mixed effects models, while the std. errors are fairly different. The estimates are similar because adding a random effect will only impact the standard error.


2.) How do the standard errors for the coefficients compare in the two models? Why do you think the standard errors are approximately the same or very different?


## The standard errors in the fixed effects model are smaller as it assumes the patients are independent, which introduces less uncertainty in the model.


3.) How do the p-values compare for the two models? 

## Following the standard error changes, the pvalues for the fixed effects model are not as statistically significant as the mixed model.


4.) Based on your answers from (1) to (3), what is the danger in assuming independence between all the observations, when, in fact, some of the observations are not independent?


## There is a danger of type I error in incorrectly assuming observations are independent, rejecting a null hypothesis that it true.


Let's next look at the first 40 fitted values for the incorrectly fitted model without a random effect for subject and the GLMM with a random effect for subject.

```{r}
cbind(fitted(mod.norand), fitted(mod3))[1:40, ]
```

5.) How do the fitted values from the two models compare? Are the fitted values from one model consistently higher or lower than the other model?


## For the most part, the fitted values for the mixed model is lower than the fitted models from the fixed model.


6.) Notice fitted values 37 through 40. These values correspond to the 10th subject in the data set (subject ID 112). Can you justify why these fitted values are much higher in the GLMM? In your justification, can you include a plot of some sort that highlights this particular subject?

## Subject ID 112 is the subject who was the outlier in the progabide data set, and I would discount them from the analysis. These fitted values using the mixed model are likely much higher as the model accounts for this ID as dependent, and much higher than the others. In the below visual you can see these outlier points in the top right of the right-most plot.


```{r}

epil_long$resid <- residuals(mod3)
epil_long$fits <- exp(predict(mod3))
ggplot(epil_long,aes(Seizures,fits)) + geom_point() + facet_wrap(~Trt) + geom_abline()


```


